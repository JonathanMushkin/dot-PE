{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "from cogwheel import data, gw_utils, gw_plotting, utils\n",
    "from dot_pe import inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic data for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "event_data_kwargs = {\n",
    "    \"detector_names\": \"HLV\",\n",
    "    \"duration\": 120.0,\n",
    "    \"asd_funcs\": [\"asd_H_O3\", \"asd_L_O3\", \"asd_V_O3\"],\n",
    "    \"tgps\": 0.0,\n",
    "    \"fmax\": 1600.0,\n",
    "}\n",
    "\n",
    "\n",
    "event_data = data.EventData.gaussian_noise(\n",
    "    eventname=\"example_eventdata\", **event_data_kwargs, seed=20250311\n",
    ")\n",
    "\n",
    "mchirp = 75\n",
    "q = 1 / 2\n",
    "\n",
    "m1, m2 = gw_utils.mchirpeta_to_m1m2(mchirp, gw_utils.q_to_eta(q))\n",
    "injection_par_dic = dict(\n",
    "    m1=m1,\n",
    "    m2=m2,\n",
    "    ra=0.5,\n",
    "    dec=0.5,\n",
    "    iota=np.pi * 1 / 3,\n",
    "    psi=1.0,\n",
    "    phi_ref=12.0,\n",
    "    s1z=0.6,\n",
    "    s2z=0.6,\n",
    "    s1x_n=0.1,\n",
    "    s1y_n=0.2,\n",
    "    s2x_n=0.3,\n",
    "    s2y_n=-0.2,\n",
    "    l1=0.0,\n",
    "    l2=0.0,\n",
    "    tgps=0.0,\n",
    "    f_ref=50.0,\n",
    "    d_luminosity=5e3,\n",
    "    t_geocenter=0.0,\n",
    ")\n",
    "\n",
    "event_data.inject_signal(injection_par_dic, \"IMRPhenomXODE\")\n",
    "\n",
    "print(event_data.injection[\"d_h\"] - event_data.injection[\"h_h\"] / 2)\n",
    "print(sum(event_data.injection[\"d_h\"] - event_data.injection[\"h_h\"] / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, load data form file\n",
    "\n",
    "`event_data = data.EventData.from_npz(filename=\"../example_eventdata.npz\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set bank folder, in the relevant mass range.\n",
    "\n",
    "See how to create mass ranges in create_sample_bank.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_folder = \"test_bank\"\n",
    "bank_folder = Path(bank_folder)\n",
    "event_dir = event_data.eventname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundir = inference.run(\n",
    "    event_dir=event_dir,\n",
    "    event=event_data,\n",
    "    bank_folder=bank_folder,\n",
    "    n_int=2**16,\n",
    "    n_ext=512,\n",
    "    n_phi=32,\n",
    "    n_t=64,\n",
    "    i_int_start=0,\n",
    "    blocksize=2**12,\n",
    "    single_detector_blocksize=2**12,\n",
    "    seed=42,\n",
    "    size_limit=10**6,\n",
    "    draw_subset=False,\n",
    "    n_draws=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundirs = sorted(\n",
    "    Path(\"example_eventdata\").glob(\"run_*\"),\n",
    "    key=lambda x: int(x.name.split(\"_\")[-1]),\n",
    ")\n",
    "\n",
    "rundir = rundirs[-1]\n",
    "summary_results = utils.read_json(rundirs[-1] / \"summary_results.json\")\n",
    "\n",
    "for k, v in summary_results.items():\n",
    "    print(k, v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_feather(rundirs[-1] / \"samples.feather\")\n",
    "params = [\"mchirp\", \"lnq\", \"chieff\", \"cumchidiff\", \"costheta_jn\", \"lnl\"]\n",
    "gw_plotting.CornerPlot(samples, params=params, smooth=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load existing results and run post-processing only\n",
    "# can be used for debugging\n",
    "\n",
    "event_data = data.EventData.from_npz(filename=rundir / \"example_eventdata.npz\")\n",
    "bank_folder = Path(\"test_bank\")\n",
    "posterior = utils.read_json(rundir / \"Posterior.json\")\n",
    "pr = posterior.prior\n",
    "# Load the intrinsic indices that were used\n",
    "intrinsic_data = np.load(rundir / \"intrinsic_samples.npz\")\n",
    "inds = intrinsic_data[\"inds\"]\n",
    "\n",
    "# Run post-processing only\n",
    "samples = inference.postprocess(\n",
    "    event_data=event_data,\n",
    "    rundir=rundir,\n",
    "    bank_folder=bank_folder,\n",
    "    n_int=2**16,\n",
    "    inds=inds,\n",
    "    n_ext=512,\n",
    "    n_phi=32,\n",
    "    pr=pr,\n",
    "    draw_subset=False,\n",
    "    n_draws=None,\n",
    ")\n",
    "\n",
    "# Save the new samples\n",
    "samples.to_feather(rundir / \"samples_postprocess_only.feather\")\n",
    "print(\n",
    "    f\"Post-processing completed. Samples saved to {rundir / 'samples_postprocess_only.feather'}\"\n",
    ")\n",
    "\n",
    "# Compare with original results\n",
    "original_samples = pd.read_feather(rundir / \"samples.feather\")\n",
    "print(f\"Original samples shape: {original_samples.shape}\")\n",
    "print(f\"New samples shape: {samples.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing results and run post-processing only\n",
    "rundir = Path(\"example_eventdata/run_3\")\n",
    "event_data = data.EventData.from_npz(filename=rundir / \"example_eventdata.npz\")\n",
    "bank_folder = Path(\"test_bank\")\n",
    "posterior = utils.read_json(rundir / \"Posterior.json\")\n",
    "pr = posterior.prior\n",
    "\n",
    "# Load the intrinsic indices that were used\n",
    "intrinsic_data = np.load(rundir / \"intrinsic_samples.npz\")\n",
    "inds = intrinsic_data[\"inds\"]\n",
    "\n",
    "# Run post-processing only\n",
    "samples = inference.postprocess(\n",
    "    event_data=event_data,\n",
    "    rundir=rundir,\n",
    "    bank_folder=bank_folder,\n",
    "    n_int=2**16,\n",
    "    inds=inds,\n",
    "    n_ext=512,\n",
    "    n_phi=32,\n",
    "    pr=pr,\n",
    "    draw_subset=False,\n",
    "    n_draws=None,\n",
    ")\n",
    "\n",
    "# Load original samples for comparison\n",
    "original_samples = pd.read_feather(rundir / \"samples.feather\")\n",
    "\n",
    "print(f\"Original shape: {original_samples.shape}\")\n",
    "print(f\"New shape: {samples.shape}\")\n",
    "print(f\"Columns match: {list(original_samples.columns) == list(samples.columns)}\")\n",
    "\n",
    "# Columns that change due to random luminosity distance sampling\n",
    "random_columns = ['d_luminosity', 'd_h_1Mpc', 'h_h_1Mpc', 'lnl']\n",
    "\n",
    "# Check for differences in specific columns (excluding random ones)\n",
    "if not original_samples.equals(samples):\n",
    "    print(\"\\nDifferences found!\")\n",
    "    \n",
    "    # Check which columns differ (excluding random columns)\n",
    "    for col in original_samples.columns:\n",
    "        if col not in random_columns and col in samples.columns:\n",
    "            if not original_samples[col].equals(samples[col]):\n",
    "                print(f\"Column '{col}' differs\")\n",
    "                print(f\"  Original first 5: {original_samples[col].head().values}\")\n",
    "                print(f\"  New first 5: {samples[col].head().values}\")\n",
    "                print(f\"  Max difference: {np.max(np.abs(original_samples[col] - samples[col]))}\")\n",
    "        elif col not in samples.columns:\n",
    "            print(f\"Column '{col}' missing in new samples\")\n",
    "    \n",
    "    # Check for extra columns in new samples\n",
    "    for col in samples.columns:\n",
    "        if col not in original_samples.columns:\n",
    "            print(f\"Extra column '{col}' in new samples\")\n",
    "else:\n",
    "    print(\"Results are identical!\")\n",
    "\n",
    "# Save the new samples for inspection\n",
    "samples.to_feather(rundir / \"samples_postprocess_only.feather\")\n",
    "print(f\"\\nNew samples saved to {rundir / 'samples_postprocess_only.feather'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
