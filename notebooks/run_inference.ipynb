{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "from cogwheel import data, gw_utils, gw_plotting, utils\n",
    "from dot_pe import inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic data for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "event_data_kwargs = {\n",
    "    \"detector_names\": \"HLV\",\n",
    "    \"duration\": 120.0,\n",
    "    \"asd_funcs\": [\"asd_H_O3\", \"asd_L_O3\", \"asd_V_O3\"],\n",
    "    \"tgps\": 0.0,\n",
    "    \"fmax\": 1600.0,\n",
    "}\n",
    "\n",
    "eventname = \"test_event\"\n",
    "\n",
    "event_data = data.EventData.gaussian_noise(\n",
    "    eventname=eventname, **event_data_kwargs, seed=20250311\n",
    ")\n",
    "\n",
    "mchirp = 75\n",
    "q = 1 / 2\n",
    "\n",
    "m1, m2 = gw_utils.mchirpeta_to_m1m2(mchirp, gw_utils.q_to_eta(q))\n",
    "injection_par_dic = dict(\n",
    "    m1=m1,\n",
    "    m2=m2,\n",
    "    ra=0.5,\n",
    "    dec=0.5,\n",
    "    iota=np.pi * 1 / 3,\n",
    "    psi=1.0,\n",
    "    phi_ref=12.0,\n",
    "    s1z=0.6,\n",
    "    s2z=0.6,\n",
    "    s1x_n=0.1,\n",
    "    s1y_n=0.2,\n",
    "    s2x_n=0.3,\n",
    "    s2y_n=-0.2,\n",
    "    l1=0.0,\n",
    "    l2=0.0,\n",
    "    tgps=0.0,\n",
    "    f_ref=50.0,\n",
    "    d_luminosity=5e3,\n",
    "    t_geocenter=0.0,\n",
    ")\n",
    "\n",
    "event_data.inject_signal(injection_par_dic, \"IMRPhenomXODE\")\n",
    "\n",
    "print(event_data.injection[\"d_h\"] - event_data.injection[\"h_h\"] / 2)\n",
    "print(sum(event_data.injection[\"d_h\"] - event_data.injection[\"h_h\"] / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, load data form file\n",
    "\n",
    "`event_data = data.EventData.from_npz(filename=\"../test_event.npz\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set bank folder, in the relevant mass range.\n",
    "\n",
    "See how to create mass ranges in create_sample_bank.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_folder = \"test_bank\"\n",
    "bank_folder = Path(bank_folder)\n",
    "event_dir = event_data.eventname\n",
    "bank = pd.read_feather(bank_folder / \"intrinsic_sample_bank.feather\")\n",
    "bank_size = len(bank)\n",
    "mchirp = gw_utils.m1m2_to_mchirp(bank[\"m1\"], bank[\"m2\"])\n",
    "\n",
    "intrinsic_samples_idx = np.where((mchirp > 60) & (mchirp < 90))[0]\n",
    "np.save(file=\"test_event/inds_in_mass_range.npy\", arr=intrinsic_samples_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsic_samples_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundir = inference.run(\n",
    "    event_dir=event_dir,\n",
    "    event=event_data,\n",
    "    bank_folder=bank_folder,\n",
    "    n_int=bank_size,\n",
    "    n_ext=512,\n",
    "    n_phi=64,\n",
    "    n_phi_incoherent=32,\n",
    "    n_t=64,\n",
    "    i_int_start=0,\n",
    "    blocksize=min(bank_size, 4096),\n",
    "    single_detector_blocksize=min(bank_size, 4096),\n",
    "    seed=42,\n",
    "    size_limit=10**6,\n",
    "    draw_subset=False,\n",
    "    n_draws=None,\n",
    "    preselected_indices=\"test_event/inds_in_mass_range.npy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundirs = sorted(\n",
    "    Path(eventname).glob(\"run_*\"),\n",
    "    key=lambda x: int(x.name.split(\"_\")[-1]),\n",
    ")\n",
    "\n",
    "rundir = rundirs[-1]\n",
    "summary_results = utils.read_json(rundirs[-1] / \"summary_results.json\")\n",
    "\n",
    "for k, v in summary_results.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_feather(rundirs[-1] / \"samples.feather\")\n",
    "params = [\"mchirp\", \"lnq\", \"chieff\", \"cumchidiff\", \"costheta_jn\", \"lnl\"]\n",
    "gw_plotting.CornerPlot(samples, params=params, smooth=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[\"mchirp\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load existing results and run post-processing only\n",
    "# can be used for debugging\n",
    "\n",
    "event_data = data.EventData.from_npz(filename=rundir / (eventname + \".npz\"))\n",
    "bank_folder = Path(\"test_bank\")\n",
    "posterior = utils.read_json(rundir / \"Posterior.json\")\n",
    "pr = posterior.prior\n",
    "# Load the intrinsic indices that were used\n",
    "intrinsic_data = np.load(rundir / \"intrinsic_samples.npz\")\n",
    "inds = intrinsic_data[\"inds\"]\n",
    "bank_size = len(pd.read_feather(bank_folder / \"intrinsic_sample_bank.feather\"))\n",
    "\n",
    "# Run post-processing only\n",
    "samples = inference.postprocess(\n",
    "    event_data=event_data,\n",
    "    rundir=rundir,\n",
    "    bank_folder=bank_folder,\n",
    "    n_int=bank_size,\n",
    "    inds=inds,\n",
    "    n_ext=512,\n",
    "    n_phi=32,\n",
    "    pr=pr,\n",
    "    draw_subset=False,\n",
    "    n_draws=None,\n",
    ")\n",
    "\n",
    "# Save the new samples\n",
    "samples.to_feather(rundir / \"samples_postprocess_only.feather\")\n",
    "print(\n",
    "    f\"Post-processing completed. Samples saved to {rundir / 'samples_postprocess_only.feather'}\"\n",
    ")\n",
    "\n",
    "# Compare with original results\n",
    "original_samples = pd.read_feather(rundir / \"samples.feather\")\n",
    "print(f\"Original samples shape: {original_samples.shape}\")\n",
    "print(f\"New samples shape: {samples.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dot-pe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
